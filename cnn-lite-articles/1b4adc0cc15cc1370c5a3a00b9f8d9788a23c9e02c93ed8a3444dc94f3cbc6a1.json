{
  "url": "https://lite.cnn.com/2026/02/27/tech/openai-has-same-redlines-as-anthropic-in-any-deal-with-the-pentagon",
  "title": "Sam Altman shares Anthropic’s concerns when it comes to working with the Pentagon | CNN Business",
  "date": "2026-03-01T07:07:42.359420+00:00",
  "authors": [
    "Hadas Gold"
  ],
  "text": "Source: CNN\n\nChatGPT maker OpenAI has the sameredlines as Anthropicwhen it comes to working with the Pentagon, an OpenAI spokesperson confirmed to CNN.\n\nThat means even if the Pentagon decides to cancel its Anthropic contract in favor of OpenAI, it’ll have to contend with the same concerns over the use of AI in autonomous weapons and mass surveillance of US citizens.\n\nOpenAI CEO Sam Altman said in an interview withCNBC on Friday morning that it’s important for companies to work with the Pentagon, “as long as it is going to comply with legal protections” and “the few red lines” that OpenAI and many in the AI industry have when it comes to AI use in the military.\n\n“For all the differences I have with Anthropic, I mostly trust them as a company, and I think they really do care about safety, and I’ve been happy that they’ve been supporting our war fighters,” Altman continued. “I’m not sure where this is going to go.”\n\nThe Pentagon declined to comment for this story.\n\nA source familiar with the situation said Altman directly approached the Pentagon this week expressing concern about Hegseth declaring Anthropic a supply chain risk or using the Defense Procurement Act to compel Anthropic to work with the military.\n\nAnthropic’s Claude system was the first AI model to be used for work on the military’s classified systems. But the Pentagon has given the company until 5:01pm on Friday to agree to drop its internal guardrails andallow its system to be used for “all lawful use.” If Anthropic doesn’t agree, it’ll lose a $200 million contract with the Pentagon and could be designated a “supply chain risk,” the same label given to companies connected to foreign adversaries.\n\nAnthropic has said it wants to work with the Pentagon, but that its worries  about the use of AI in autonomous weapons and mass surveillance stem from concerns the technology is still unreliable in these cases. Current laws and regulations do not properly account for advancements in AI,the company also said.\n\nIn a memo to OpenAI staff on Thursday obtained by CNN, Altman said “this is no longer just an issue between Anthropic and the DoW; this is an issue for the whole industry and it is important to clarify our stance.” He added that OpenAI has a proposal for the Pentagon that they believe will allow “our models to be deployed in classified environments and that fits with our principles” that could work for other AI labs as well.\n\n“We believe this dispute isn’t about how AI will be used, but about control. We believe that a private US company cannot be more powerful than the democratically-elected US government, although companies can have lots of input and influence,” Altman continued in the memo, first reported by theWall Street Journal.\n\n“The way the current situation has gone risks our national security, and also risks the government resorting to actions which could risk American leadership in AI. We would like to try to help de-escalate things,” Altman wrote.\n\nOpenAI is one of several AI companies to havesigned dealswith the Pentagon last summer to “develop prototype frontier AI capabilities to address critical national security challenges in both warfighting and enterprise domains,” thePentagon saidat the time. But Anthropic’s Claude was the only model used on the military’s classified system until recently. A Pentagon official told CNN this week that Elon Musk’s Grok is now “on board with being used in classified setting,” while the other companies including OpenAI were “close”.\n\nEditor’s note: A comment previously provided by the Pentagon about the department’s work to expand its arsenal of AI capabilities, and efforts to ensure safety and security of AI models, has been removed from this story after the Pentagon said it was provided mistakenly.\n\nCNN’s Haley Britzky contributed to this report.\n\nSee Full Web Article",
  "links": [
    {
      "url": "https://www.cnn.com/2026/02/27/tech/anthropic-pentagon-deadline",
      "text": "redlines as Anthropic"
    },
    {
      "url": "https://www.wsj.com/tech/ai/openais-sam-altman-calls-for-de-escalation-in-anthropic-showdown-with-hegseth-03ecbac8?st=xzDmVH",
      "text": "Wall Street Journal"
    },
    {
      "url": "https://openai.com/global-affairs/introducing-openai-for-government/",
      "text": "signed deals"
    },
    {
      "url": "https://www.ai.mil/latest/news-press/pr-view/article/4242822/cdao-announces-partnerships-with-frontier-ai-companies-to-address-national-secu/",
      "text": "Pentagon said"
    }
  ],
  "hash": "1b4adc0cc15cc1370c5a3a00b9f8d9788a23c9e02c93ed8a3444dc94f3cbc6a1",
  "scraped_at": "2026-03-01T07:07:42.359432+00:00"
}